{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e6ef4e-a00e-4887-b477-7be869cf6e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Using cached pymongo-4.11.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Using cached pymongo-4.11.1-cp312-cp312-win_amd64.whl (882 kB)\n",
      "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.11.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e487ba81-2ddc-4f10-85b7-1e39f29a9c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.78-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (2.4.0)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (6.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Using cached ultralytics-8.3.78-py3-none-any.whl (921 kB)\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: sympy, torch, ultralytics-thop, torchvision, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0\n",
      "    Uninstalling torchvision-0.19.0:\n",
      "      Successfully uninstalled torchvision-0.19.0\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 ultralytics-8.3.78 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "descript-audiotools 0.7.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.4 which is incompatible.\n",
      "torchaudio 2.4.0 requires torch==2.4.0, but you have torch 2.6.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f85827-794f-44dd-b05a-2ce6206dd6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 dress, 232.6ms\n",
      "Speed: 6.9ms preprocess, 232.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ‚úÖ Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://maryambhatti900:Hello123*@cluster0.hw8qz.mongodb.net/\")\n",
    "db = client[\"fashion_db\"]\n",
    "collection = db[\"products\"]\n",
    "\n",
    "# ‚úÖ Load YOLO Model\n",
    "yolo_model = YOLO(\"best.pt\")\n",
    "\n",
    "# ‚úÖ Load Video\n",
    "cap = cv2.VideoCapture(\"2.mp4\")  # Replace with your video file\n",
    "\n",
    "# ‚úÖ SIFT Feature Detector\n",
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# Global variables\n",
    "selected_bbox = None\n",
    "frame_copy = None\n",
    "\n",
    "def fetch_related_images(label):\n",
    "    \"\"\"Fetch all related images from MongoDB based on object label.\"\"\"\n",
    "    category_map = {\"dress\": \"Dresses\", \"shoe\": \"Shoes\", \"bag\": \"Bags\"}\n",
    "    category = category_map.get(label.lower(), label)\n",
    "    product_data = collection.find_one({category: {\"$exists\": True}}, {category: 1})\n",
    "    if not product_data or category not in product_data:\n",
    "        print(f\"‚ö†Ô∏è No records found for category: {category}\")\n",
    "        return []\n",
    "    images = []\n",
    "    for product in product_data[category]:\n",
    "        img_paths = [f\"db/{img}\" for img in product[\"images\"]]\n",
    "        images.append((product, img_paths))\n",
    "    return images\n",
    "\n",
    "def find_best_match(target_img, related_images):\n",
    "    \"\"\"Find the best match using SIFT among all product images.\"\"\"\n",
    "    target_gray = cv2.cvtColor(target_img, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints_target, descriptors_target = sift.detectAndCompute(target_gray, None)\n",
    "    best_match_product = None\n",
    "    max_good_matches = 0\n",
    "    match_counts = {}\n",
    "    \n",
    "    for product, img_paths in related_images:\n",
    "        total_good_matches = 0\n",
    "        for img_path in img_paths:\n",
    "            db_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if db_img is None:\n",
    "                continue\n",
    "            keypoints_db, descriptors_db = sift.detectAndCompute(db_img, None)\n",
    "            if descriptors_target is None or descriptors_db is None:\n",
    "                continue\n",
    "            matches = bf.knnMatch(descriptors_target, descriptors_db, k=2)\n",
    "            good_matches = [m for m, n in matches if m.distance < 0.5 * n.distance]\n",
    "            total_good_matches += len(good_matches)\n",
    "        match_counts[product.get('name', 'Unknown')] = total_good_matches\n",
    "        if total_good_matches > max_good_matches:\n",
    "            max_good_matches = total_good_matches\n",
    "            best_match_product = product\n",
    "    return best_match_product, match_counts\n",
    "\n",
    "def plot_match_results(match_counts, cropped_obj):\n",
    "    \"\"\"Plot the number of good matches per product and the selected object.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Plot the selected object\n",
    "    axes[0].imshow(cv2.cvtColor(cropped_obj, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(\"Selected Object\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # Plot match results\n",
    "    if match_counts:\n",
    "        axes[1].bar(match_counts.keys(), match_counts.values(), color='skyblue')\n",
    "        axes[1].set_xlabel(\"Product Name\")\n",
    "        axes[1].set_ylabel(\"Number of Good Matches\")\n",
    "        axes[1].set_title(\"SIFT Feature Matching Results\")\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    \"\"\"Handle mouse click event.\"\"\"\n",
    "    global selected_bbox, frame_copy\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        results = yolo_model(frame_copy)\n",
    "        all_boxes = []\n",
    "        class_names = results[0].names\n",
    "        for result in results:\n",
    "            for box in result.boxes.data:\n",
    "                all_boxes.append(box)\n",
    "        if all_boxes:\n",
    "            selected_bbox, obj_type = get_closest_box(x, y, all_boxes, class_names)\n",
    "            if selected_bbox:\n",
    "                x1, y1, x2, y2 = selected_bbox\n",
    "                cropped_obj = frame_copy[y1:y2, x1:x2]\n",
    "                related_images = fetch_related_images(obj_type)\n",
    "                if related_images:\n",
    "                    best_product, match_counts = find_best_match(cropped_obj, related_images)\n",
    "                    plot_match_results(match_counts, cropped_obj)\n",
    "                    if best_product:\n",
    "                        print(f\"‚úÖ Best Match Found for {obj_type}:\")\n",
    "                        print(f\"üìå Name: {best_product.get('name', 'Unknown')}\")\n",
    "                        print(f\"üí≤ Price: {best_product.get('price', 'Unknown')}\")\n",
    "                        print(f\"üñº Images: {best_product.get('images', [])}\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå No matching product found for {obj_type}.\")\n",
    "                else:\n",
    "                    print(f\"‚ùå No related products found for {obj_type}.\")\n",
    "                print(f\"üîç Object Type: {obj_type}\")\n",
    "\n",
    "def get_closest_box(click_x, click_y, boxes, class_names):\n",
    "    \"\"\"Find the closest bounding box to the clicked point.\"\"\"\n",
    "    min_dist = float(\"inf\")\n",
    "    closest_box = None\n",
    "    closest_label = None\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box[:4])\n",
    "        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "        dist = (center_x - click_x) ** 2 + (center_y - click_y) ** 2\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_box = (x1, y1, x2, y2)\n",
    "            closest_label = class_names[int(box[5].item())]\n",
    "    return closest_box, closest_label\n",
    "\n",
    "cv2.namedWindow(\"Video\")\n",
    "cv2.setMouseCallback(\"Video\", on_mouse_click)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_copy = frame.copy()\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6645457e-c17e-4f39-a840-3b69ac868335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset\\2_0000.jpg\n",
      "Saved dataset\\2_0001.jpg\n",
      "Saved dataset\\2_0002.jpg\n",
      "Saved dataset\\2_0003.jpg\n",
      "Saved dataset\\2_0004.jpg\n",
      "Saved dataset\\2_0005.jpg\n",
      "Saved dataset\\2_0006.jpg\n",
      "Saved dataset\\2_0007.jpg\n",
      "Saved dataset\\2_0008.jpg\n",
      "Saved dataset\\2_0009.jpg\n",
      "Saved dataset\\2_0010.jpg\n",
      "Saved dataset\\2_0011.jpg\n",
      "Saved dataset\\2_0012.jpg\n",
      "Saved dataset\\2_0013.jpg\n",
      "Saved dataset\\2_0014.jpg\n",
      "Saved dataset\\2_0015.jpg\n",
      "Saved dataset\\2_0016.jpg\n",
      "Saved dataset\\2_0017.jpg\n",
      "Saved dataset\\2_0018.jpg\n",
      "Saved dataset\\2_0019.jpg\n",
      "Saved dataset\\2_0020.jpg\n",
      "Saved dataset\\2_0021.jpg\n",
      "Saved dataset\\2_0022.jpg\n",
      "Saved dataset\\2_0023.jpg\n",
      "Saved dataset\\2_0024.jpg\n",
      "Saved dataset\\2_0025.jpg\n",
      "Saved dataset\\2_0026.jpg\n",
      "Saved dataset\\2_0027.jpg\n",
      "Saved dataset\\2_0028.jpg\n",
      "Saved dataset\\2_0029.jpg\n",
      "Saved dataset\\2_0030.jpg\n",
      "Saved dataset\\2_0031.jpg\n",
      "Saved dataset\\2_0032.jpg\n",
      "Saved dataset\\2_0033.jpg\n",
      "Saved dataset\\2_0034.jpg\n",
      "Saved dataset\\2_0035.jpg\n",
      "Saved dataset\\2_0036.jpg\n",
      "Saved dataset\\2_0037.jpg\n",
      "Saved dataset\\2_0038.jpg\n",
      "Saved dataset\\2_0039.jpg\n",
      "Saved dataset\\2_0040.jpg\n",
      "Saved dataset\\2_0041.jpg\n",
      "Saved dataset\\2_0042.jpg\n",
      "Saved dataset\\2_0043.jpg\n",
      "Saved dataset\\2_0044.jpg\n",
      "Saved dataset\\2_0045.jpg\n",
      "Saved dataset\\2_0046.jpg\n",
      "Saved dataset\\2_0047.jpg\n",
      "Saved dataset\\2_0048.jpg\n",
      "Saved dataset\\2_0049.jpg\n",
      "Saved dataset\\2_0050.jpg\n",
      "Saved dataset\\2_0051.jpg\n",
      "Saved dataset\\2_0052.jpg\n",
      "Saved dataset\\2_0053.jpg\n",
      "Saved dataset\\2_0054.jpg\n",
      "Saved dataset\\2_0055.jpg\n",
      "Saved dataset\\2_0056.jpg\n",
      "Saved dataset\\2_0057.jpg\n",
      "Saved dataset\\2_0058.jpg\n",
      "Saved dataset\\2_0059.jpg\n",
      "Saved dataset\\2_0060.jpg\n",
      "Saved dataset\\2_0061.jpg\n",
      "Saved dataset\\2_0062.jpg\n",
      "Saved dataset\\2_0063.jpg\n",
      "Saved dataset\\2_0064.jpg\n",
      "Saved dataset\\2_0065.jpg\n",
      "Saved dataset\\2_0066.jpg\n",
      "Saved dataset\\2_0067.jpg\n",
      "Saved dataset\\2_0068.jpg\n",
      "Saved dataset\\2_0069.jpg\n",
      "Saved dataset\\2_0070.jpg\n",
      "Saved dataset\\2_0071.jpg\n",
      "Saved dataset\\2_0072.jpg\n",
      "Saved dataset\\2_0073.jpg\n",
      "Saved dataset\\2_0074.jpg\n",
      "Saved dataset\\2_0075.jpg\n",
      "Saved dataset\\2_0076.jpg\n",
      "Saved dataset\\2_0077.jpg\n",
      "Saved dataset\\2_0078.jpg\n",
      "Saved dataset\\2_0079.jpg\n",
      "Saved dataset\\2_0080.jpg\n",
      "Saved dataset\\2_0081.jpg\n",
      "Saved dataset\\2_0082.jpg\n",
      "Saved dataset\\2_0083.jpg\n",
      "Saved dataset\\2_0084.jpg\n",
      "Saved dataset\\2_0085.jpg\n",
      "Saved dataset\\2_0086.jpg\n",
      "Saved dataset\\2_0087.jpg\n",
      "Saved dataset\\2_0088.jpg\n",
      "Saved dataset\\2_0089.jpg\n",
      "Saved dataset\\2_0090.jpg\n",
      "Saved dataset\\2_0091.jpg\n",
      "Saved dataset\\2_0092.jpg\n",
      "Saved dataset\\2_0093.jpg\n",
      "Saved dataset\\2_0094.jpg\n",
      "Saved dataset\\2_0095.jpg\n",
      "Saved dataset\\2_0096.jpg\n",
      "Saved dataset\\2_0097.jpg\n",
      "Saved dataset\\2_0098.jpg\n",
      "Saved dataset\\2_0099.jpg\n",
      "Saved dataset\\2_0100.jpg\n",
      "Saved dataset\\2_0101.jpg\n",
      "Saved dataset\\2_0102.jpg\n",
      "Saved dataset\\2_0103.jpg\n",
      "Saved dataset\\2_0104.jpg\n",
      "Saved dataset\\2_0105.jpg\n",
      "Saved dataset\\2_0106.jpg\n",
      "Saved dataset\\2_0107.jpg\n",
      "Saved dataset\\2_0108.jpg\n",
      "Saved dataset\\2_0109.jpg\n",
      "Saved dataset\\2_0110.jpg\n",
      "Saved dataset\\2_0111.jpg\n",
      "Saved dataset\\2_0112.jpg\n",
      "Saved dataset\\2_0113.jpg\n",
      "Saved dataset\\2_0114.jpg\n",
      "Saved dataset\\2_0115.jpg\n",
      "Saved dataset\\2_0116.jpg\n",
      "Saved dataset\\2_0117.jpg\n",
      "Saved dataset\\2_0118.jpg\n",
      "Saved dataset\\2_0119.jpg\n",
      "Saved dataset\\2_0120.jpg\n",
      "Saved dataset\\2_0121.jpg\n",
      "Saved dataset\\2_0122.jpg\n",
      "Saved dataset\\2_0123.jpg\n",
      "Saved dataset\\2_0124.jpg\n",
      "Saved dataset\\2_0125.jpg\n",
      "Saved dataset\\2_0126.jpg\n",
      "Saved dataset\\2_0127.jpg\n",
      "Saved dataset\\2_0128.jpg\n",
      "Saved dataset\\2_0129.jpg\n",
      "Saved dataset\\2_0130.jpg\n",
      "Saved dataset\\2_0131.jpg\n",
      "Saved dataset\\2_0132.jpg\n",
      "Saved dataset\\2_0133.jpg\n",
      "Saved dataset\\2_0134.jpg\n",
      "Saved dataset\\2_0135.jpg\n",
      "Extraction complete. 136 frames saved.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get frames per second\n",
    "    frame_count = 0\n",
    "    sec_count = 0\n",
    "    frames_per_sec = 3  # Number of frames to save per second\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Stop if no more frames\n",
    "        \n",
    "        if frame_count % (fps // frames_per_sec) == 0:  # Save three frames per second\n",
    "            frame_filename = os.path.join(output_folder, f\"2_{sec_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            print(f\"Saved {frame_filename}\")\n",
    "            sec_count += 1\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    # Release video capture object\n",
    "    cap.release()\n",
    "    print(f\"Extraction complete. {sec_count} frames saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"2.mp4\"  # Replace with your video file path\n",
    "    output_folder = \"dataset\"  # Folder to save frames\n",
    "    extract_frames(video_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9658601-4c4f-4494-85e6-281a0f366163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
